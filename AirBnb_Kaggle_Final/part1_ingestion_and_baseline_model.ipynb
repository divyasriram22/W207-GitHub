{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cendy\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "c:\\Users\\cendy\\Anaconda3\\lib\\site-packages\\sklearn\\grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# IMPORTS \n",
    "\n",
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# Import a bunch of libraries.\n",
    "import time\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from matplotlib.ticker import MultipleLocator\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in csv and create arrays\n",
<<<<<<< HEAD
    "\n",
    "#To-DO update file path\n",
    "\n",
    "users_train_raw = pd.read_csv('/Users/giles/Documents/MIDS/w207/w207_group_project/zip_files/train_users_2.csv')\n",
    "sessions_raw = pd.read_csv('/Users/giles/Documents/MIDS/w207/w207_group_project/zip_files/sessions.csv')\n",
    "demographics = pd.read_csv('/Users/giles/Documents/MIDS/w207/w207_group_project/zip_files/age_gender_bkts.csv')\n",
    "countries = pd.read_csv('/Users/giles/Documents/MIDS/w207/w207_group_project/zip_files/countries.csv')\n",
    "test = pd.read_csv('/Users/giles/Documents/MIDS/w207/w207_group_project/zip_files/test_users.csv')\n",
=======
    "users_train_raw = pd.read_csv('./zip_files/train_users_2.csv.zip')\n",
    "sessions_raw = pd.read_csv('./zip_files/sessions.csv.zip')\n",
    "demographics = pd.read_csv('./zip_files/age_gender_bkts.csv.zip')\n",
    "countries = pd.read_csv('./zip_files/countries.csv.zip')\n",
    "test = pd.read_csv('./zip_files/test_users.csv.zip')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# split users_train_raw into train and dev csv files\n",
>>>>>>> 52b56421f79846616eb92ae34f61c585a8180d10
    "\n",
    "# Shuffle data\n",
    "np.random.seed(0)\n",
    "shuffle = np.random.permutation(np.arange(users_train_raw.shape[0]))\n",
    "len(shuffle)\n",
    "x = users_train_raw.reindex(shuffle)\n",
    "\n",
    "# Split into train and dev.\n",
    "dev_data = x[:25000]\n",
    "train_data = x[25000:]\n",
    "\n",
    "# save to csv\n",
    "dev_data.to_csv(\"./train_dev_data/dev_data.csv\",  index=False)\n",
    "train_data.to_csv(\"./train_dev_data/train_data.csv\",  index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "213451\n",
      "25000\n",
      "188451\n"
     ]
    }
   ],
   "source": [
    "print(len(users_train_raw))\n",
    "print(len(dev_data))\n",
    "print(len(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'user_training_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7d70866a2b78>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mtrain_data_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmerge\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0musers_train_raw\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msessions_raw\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mon\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'id'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#Creates data frame with all user data merged with session data. Note each user has multiple sessions.\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_labels_full\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0muser_training_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'country_destination'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# Creates labes for the merged training data set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtrain_data_full\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdrop\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'country_destination'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minplace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#remove labels from training set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'user_training_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Note that \"basic\" data are those sets of \"user data\" where the \"sessions data\" has not yet been added\n",
    "# \"Full\" data is where user and sessions data have been merged\n",
    "\n",
    "\n",
    "# TO-DO: Make Dev Set\n",
    "\n",
    "\n",
    "sessions_raw.rename(columns={'user_id': 'id'}, inplace=True)  #Rename user_id column to id for easier merging\n",
    "\n",
    "train_data_full = pd.merge(users_train_raw, sessions_raw,on='id') #Creates data frame with all user data merged with session data. Note each user has multiple sessions.\n",
    "train_labels_full = user_training_data['country_destination'] # Creates labes for the merged training data set\n",
    "train_data_full.drop('country_destination',axis=1,inplace=True) #remove labels from training set\n",
    "\n",
    "train_data_basic = users_train_raw #creating a duplicate to manipulate\n",
    "train_basic_labels = train_data_basic['country_destination'] #creates a df of labels \n",
    "train_data_basic.drop('country_destination', axis=1, inplace=True) #remove labels from training set\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Turn Pandas DFs into Numpy Arrays to be used in SKLearn\n",
    "\n",
    "train_labels_full_array = train_labels_full.iloc[1:].values\n",
    "train_basic_labels_array = train_basic_labels.iloc[1:].values\n",
    "\n",
    "train_data_basic_array = train_data_basic.iloc[0:].values\n",
    "train_data_full_array = train_data_full.iloc[0:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "62096"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
