{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giles/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/giles/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# General libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Draw inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set_context(\"notebook\", font_scale=1.5)\n",
    "\n",
    "# Sklearn preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Sklearn libraries.\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giles/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (213451, 541)\n",
      "test shape: (62096, 540)\n"
     ]
    }
   ],
   "source": [
    "# Load full data set (combined with actions)\n",
    "train = pd.read_csv('../data/train_combined_actions.zip')\n",
    "print(\"train shape:\", train.shape)\n",
    "\n",
    "# load test data\n",
    "test = pd.read_csv('../data/test_combined_actions.zip')\n",
    "print(\"test shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_account_created</th>\n",
       "      <th>timestamp_first_active</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>signup_method</th>\n",
       "      <th>signup_flow</th>\n",
       "      <th>language</th>\n",
       "      <th>affiliate_channel</th>\n",
       "      <th>affiliate_provider</th>\n",
       "      <th>...</th>\n",
       "      <th>view_resolutions</th>\n",
       "      <th>view_search_results</th>\n",
       "      <th>view_security_checks</th>\n",
       "      <th>view_user_real_names</th>\n",
       "      <th>wishlist</th>\n",
       "      <th>wishlist_content_update</th>\n",
       "      <th>wishlist_note</th>\n",
       "      <th>your_listings</th>\n",
       "      <th>your_reservations</th>\n",
       "      <th>your_trips</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5uwns89zht</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>20140701000006</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>35.0</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>jtl0dijy2j</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>20140701000051</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xx0ulgorjt</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>20140701000148</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6c6puo6ix0</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>20140701000215</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>czqhjk3yfe</td>\n",
       "      <td>2014-07-01</td>\n",
       "      <td>20140701000305</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 540 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           id date_account_created  timestamp_first_active     gender   age  \\\n",
       "0  5uwns89zht           2014-07-01          20140701000006     FEMALE  35.0   \n",
       "1  jtl0dijy2j           2014-07-01          20140701000051  -unknown-   NaN   \n",
       "2  xx0ulgorjt           2014-07-01          20140701000148  -unknown-   NaN   \n",
       "3  6c6puo6ix0           2014-07-01          20140701000215  -unknown-   NaN   \n",
       "4  czqhjk3yfe           2014-07-01          20140701000305  -unknown-   NaN   \n",
       "\n",
       "  signup_method  signup_flow language affiliate_channel affiliate_provider  \\\n",
       "0      facebook            0       en            direct             direct   \n",
       "1         basic            0       en            direct             direct   \n",
       "2         basic            0       en            direct             direct   \n",
       "3         basic            0       en            direct             direct   \n",
       "4         basic            0       en            direct             direct   \n",
       "\n",
       "      ...     view_resolutions view_search_results view_security_checks  \\\n",
       "0     ...                  0.0                 3.0                  0.0   \n",
       "1     ...                  0.0                 5.0                  0.0   \n",
       "2     ...                  0.0                48.0                  0.0   \n",
       "3     ...                  0.0                 1.0                  0.0   \n",
       "4     ...                  0.0                 0.0                  0.0   \n",
       "\n",
       "  view_user_real_names  wishlist wishlist_content_update  wishlist_note  \\\n",
       "0                  0.0       0.0                     0.0            0.0   \n",
       "1                  0.0       0.0                     0.0            0.0   \n",
       "2                  0.0       0.0                     6.0            0.0   \n",
       "3                  0.0       0.0                     3.0            0.0   \n",
       "4                  0.0       0.0                     1.0            0.0   \n",
       "\n",
       "  your_listings your_reservations  your_trips  \n",
       "0           0.0               0.0         0.0  \n",
       "1           0.0               0.0         0.0  \n",
       "2           0.0               0.0         0.0  \n",
       "3           0.0               0.0         0.0  \n",
       "4           0.0               0.0         0.0  \n",
       "\n",
       "[5 rows x 540 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full dataset shape: (135911, 26)\n",
      "dev labels shape (8850,)\n",
      "train_labels shape (64965,)\n",
      "features: ['id', 'date_account_created', 'timestamp_first_active', 'gender', 'age', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser', 'month_created', 'season_created', 'year_created', 'bin_age', 'bin_lang', 'days_since_creation', 'first_hour', 'count_actions', 'number_devices', 'longest_session', 'total_time', 'last_action']\n"
     ]
    }
   ],
   "source": [
    "# subset full data set to only include users that have sessions data, remove action counts for now \n",
    "mod_train = train[train.count_actions.isnull() != True]\n",
    "mod_train = mod_train.reset_index().iloc[: , 1:]\n",
    "\n",
    "# Shuffle training set\n",
    "shuffle = np.random.permutation(np.arange(mod_train.shape[0]))\n",
    "mod_train = mod_train.reindex(shuffle)\n",
    "\n",
    "# Split labels from training set\n",
    "train_labels = mod_train['country_destination']\n",
    "train_data = mod_train.drop('country_destination', axis=1)\n",
    "\n",
    "# Concatenate test data (so able to binarize categorical features later)\n",
    "data = pd.concat((train_data, test))\n",
    "\n",
    "# remove action features\n",
    "col = data.columns.get_loc(\"last_action\") # last column index before action columns begin\n",
    "data = data.iloc[: , :col+1]\n",
    "\n",
    "# Define row index on where to split full dataset for dev, train, and test\n",
    "dev_cutoff = 8850   # 12% of training data\n",
    "test_cutoff = mod_train.shape[0]\n",
    "\n",
    "dev_labels, train_labels = train_labels[:dev_cutoff], train_labels[dev_cutoff:]\n",
    "\n",
    "print(\"full dataset shape:\", data.shape)\n",
    "print(\"dev labels shape\", dev_labels.shape)\n",
    "print(\"train_labels shape\", train_labels.shape)\n",
    "print(\"features:\", list(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73815, 541)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mod_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64965,)\n",
      "(8850,)\n",
      "{'NDF': 0, 'US': 1, 'non-US': 2}\n"
     ]
    }
   ],
   "source": [
    "# Output 3 classes: NDF, US, Non-US\n",
    "def country(col):\n",
    "    if col == 'NDF':\n",
    "        return \"NDF\"\n",
    "    elif col == 'US':\n",
    "        return 'US'\n",
    "    else:\n",
    "        return 'non-US'\n",
    "    \n",
    "t = train_labels.apply(country)\n",
    "d = dev_labels.apply(country)\n",
    "\n",
    "# Convert labels to numeric\n",
    "le = preprocessing.LabelEncoder() # Initialize label_encoder\n",
    "t_lab, d_lab = le.fit_transform(t), le.fit_transform(d)\n",
    "\n",
    "print(t_lab.shape)\n",
    "print(d_lab.shape)\n",
    "\n",
    "country_code = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(country_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating through features using Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Feature: bin_age\n",
      "L1 num cols:  5 score: 0.602824858757\n",
      "L2 num cols:  5 score: 0.602824858757\n",
      "[[5335 2455 1060]\n",
      " [   0    0    0]\n",
      " [   0    0    0]]\n",
      "\n",
      "Added Feature: first_browser\n",
      "L1 num cols:  45 score: 0.610847457627\n",
      "L2 num cols:  45 score: 0.610847457627\n",
      "[[4380 1429  664]\n",
      " [ 954 1026  396]\n",
      " [   1    0    0]]\n",
      "\n",
      "Added Feature: gender\n",
      "L1 num cols:  49 score: 0.620677966102\n",
      "L2 num cols:  49 score: 0.620790960452\n",
      "[[4728 1689  754]\n",
      " [ 606  766  306]\n",
      " [   1    0    0]]\n",
      "\n",
      "Added Feature: signup_method\n",
      "L1 num cols:  53 score: 0.656271186441\n",
      "L2 num cols:  53 score: 0.656271186441\n",
      "[[4583 1230  578]\n",
      " [ 752 1225  482]\n",
      " [   0    0    0]]\n",
      "\n",
      "Added Feature: last_action\n",
      "L1 num cols:  185 score: 0.664971751412\n",
      "L2 num cols:  185 score: 0.664858757062\n",
      "[[4620 1191  570]\n",
      " [ 715 1264  490]\n",
      " [   0    0    0]]\n",
      "\n",
      "Added Feature: count_actions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\cendy\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:73: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "c:\\Users\\cendy\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:74: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "c:\\Users\\cendy\\Anaconda3\\lib\\site-packages\\ipykernel\\__main__.py:75: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 num cols:  186 score: 0.664745762712\n",
      "L2 num cols:  186 score: 0.664971751412\n",
      "[[4621 1191  566]\n",
      " [ 713 1264  494]\n",
      " [   1    0    0]]\n",
      "14.860193967819214\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "def binarize(data, devcut, testcut, column): \n",
    "    dev_bin = pd.get_dummies(data[column])[:devcut]\n",
    "    train_bin = pd.get_dummies(data[column])[devcut:testcut]\n",
    "    test_bin = pd.get_dummies(data[column])[testcut:]\n",
    "    return dev_bin, train_bin, test_bin\n",
    "\n",
    "def logreg(c, penalty, train, train_label, dev, dev_label):\n",
    "    lm = LogisticRegression(C = c, penalty = penalty)\n",
    "    lm.fit(tr, t_lab)\n",
    "    score = lm.score(d, d_lab)\n",
    "    return lm, score\n",
    "    \n",
    "cat_feat = ['bin_age', 'first_browser', 'gender', 'signup_method', 'last_action']\n",
    "# cat_feat = ['bin_age', 'first_browser', 'gender', 'signup_method', 'last_action', \n",
    "#             'season_created', 'first_device_type', 'signup_app', 'affiliate_channel', 'first_hour']\n",
    "\n",
    "# underperforming categorical variables: \n",
    "# 'season_created', 'first_device_type', signup_app', 'affiliate_channel', 'first_hour'\n",
    "\n",
    "# Initialize with first feature column \n",
    "d, tr, te = binarize(data, dev_cutoff, test_cutoff, cat_feat[0])\n",
    "\n",
    "print(\"First Feature:\", cat_feat[0])\n",
    "lm1, score1 = logreg(50, \"l1\", tr, t_lab, d, d_lab) # Run logreg with l1 penalty\n",
    "print(\"L1 num cols: \", tr.shape[1], \"score:\", score1)\n",
    "\n",
    "lm2, score2 = logreg(50, \"l2\", tr, t_lab, d, d_lab) # Run logreg with l2 penalty\n",
    "print(\"L2 num cols: \", tr.shape[1], \"score:\", score2)\n",
    "\n",
    "pred = lm2.predict(d)\n",
    "conf = confusion_matrix(pred, d_lab)\n",
    "print(conf)\n",
    "\n",
    "d2, tr2, te2 = binarize(data, dev_cutoff, test_cutoff, cat_feat[2])\n",
    "\n",
    "# Binarize categorical features, add to dataset, run logistic regression on binarized features\n",
    "for x in cat_feat[1:]:\n",
    "    d_bin, tr_bin, te_bin = binarize(data, dev_cutoff, test_cutoff, x)\n",
    "    d = np.concatenate((d, d_bin), axis=1)\n",
    "    tr = np.concatenate((tr, tr_bin), axis=1)\n",
    "    te = np.concatenate((te, te_bin), axis=1)\n",
    "\n",
    "    # Run logistic regression on data set with added feature\n",
    "    print(\"\\nAdded Feature:\", x)\n",
    "    lm1, score1 = logreg(50, \"l1\", tr, t_lab, d, d_lab)\n",
    "    print(\"L1 num cols: \", tr.shape[1], \"score:\", score1)\n",
    "    lm2, score2 = logreg(50, \"l2\", tr, t_lab, d, d_lab)\n",
    "    print(\"L2 num cols: \", tr.shape[1], \"score:\", score2)\n",
    "\n",
    "    pred = lm2.predict(d)\n",
    "    conf = confusion_matrix(pred, d_lab)\n",
    "    print(conf)\n",
    "\n",
    "# underperforming numerical features:\n",
    "# 'days_since_creation', 'total_time', 'number_devices', 'longest_session', 'request_photography'\n",
    "\n",
    "# num_feat = ['count_actions', 'days_since_creation', 'total_time', \n",
    "#             'number_devices', 'longest_session']\n",
    "\n",
    "num_feat = ['count_actions']\n",
    "\n",
    "for y in num_feat:\n",
    "    # get column and fill in NaNs with training data column mean\n",
    "    mean = np.mean(data[y][dev_cutoff:test_cutoff])\n",
    "    \n",
    "    tr_col = data[y][dev_cutoff:test_cutoff].fillna(mean)\n",
    "    d_col = data[y][:dev_cutoff].fillna(mean)\n",
    "    te_col = data[y][test_cutoff:].fillna(mean)\n",
    "    \n",
    "    tr_col = tr_col.reshape(tr.shape[0], 1)\n",
    "    d_col = d_col.reshape(d.shape[0], 1)\n",
    "    te_col = te_col.reshape(te.shape[0], 1)\n",
    "    \n",
    "    # add column to previous training set\n",
    "    tr = np.concatenate((tr, tr_col), axis=1)\n",
    "    d = np.concatenate((d, d_col), axis=1)\n",
    "    te = np.concatenate((te, te_col), axis=1)\n",
    "\n",
    "    # Run logistic regression on data set with added feature\n",
    "    print(\"\\nAdded Feature:\", y)\n",
    "    lm1, score1 = logreg(50, \"l1\", tr, t_lab, d, d_lab)\n",
    "    print(\"L1 num cols: \", tr.shape[1], \"score:\", score1)\n",
    "    lm2, score2 = logreg(50, \"l2\", tr, t_lab, d, d_lab)\n",
    "    print(\"L2 num cols: \", tr.shape[1], \"score:\", score2)\n",
    "\n",
    "    pred = lm2.predict(d)\n",
    "    conf = confusion_matrix(pred, d_lab)\n",
    "    print(conf)\n",
    "    \n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L1 num cols:  186,  C: 0.5,  score: 0.6650\n",
      "L2 num cols:  186,  C: 0.5,  score: 0.6654\n",
      "[[4618 1188  564]\n",
      " [ 716 1267  496]\n",
      " [   1    0    0]]\n",
      "\n",
      "L1 num cols:  186,  C:  1,  score: 0.6650\n",
      "L2 num cols:  186,  C:  1,  score: 0.6650\n",
      "[[4620 1190  566]\n",
      " [ 714 1265  494]\n",
      " [   1    0    0]]\n",
      "\n",
      "L1 num cols:  186,  C: 10,  score: 0.6649\n",
      "L2 num cols:  186,  C: 10,  score: 0.6649\n",
      "[[4617 1188  567]\n",
      " [ 717 1267  493]\n",
      " [   1    0    0]]\n",
      "\n",
      "L1 num cols:  186,  C: 50,  score: 0.6649\n",
      "L2 num cols:  186,  C: 50,  score: 0.6650\n",
      "[[4618 1189  567]\n",
      " [ 716 1266  493]\n",
      " [   1    0    0]]\n",
      "\n",
      "L1 num cols:  186,  C: 100,  score: 0.6647\n",
      "L2 num cols:  186,  C: 100,  score: 0.6647\n",
      "[[4618 1190  567]\n",
      " [ 716 1265  493]\n",
      " [   1    0    0]]\n",
      "\n",
      "Best L1 c: 0.5 score: 0.664971751412\n",
      "Best L2 c: 0.5 score: 0.665423728814\n",
      "23.81705641746521\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# Run last model and iterate over Cs\n",
    "Cs = [0.5, 1, 10, 50, 100]\n",
    "\n",
    "max1, max2 = 0, 0\n",
    "c1, c2 = 0, 0\n",
    "\n",
    "for c in Cs: \n",
    "    lm1, score1 = logreg(c, \"l1\", tr, t_lab, d, d_lab)\n",
    "    print(\"\\nL1 num cols: %4s,  C: %2s,  score: %.4f\" %(tr.shape[1], c, score1))\n",
    "    \n",
    "    lm2, score2 = logreg(c, \"l2\", tr, t_lab, d, d_lab)\n",
    "    print(\"L2 num cols: %4s,  C: %2s,  score: %.4f\" %(tr.shape[1], c, score2))\n",
    "\n",
    "    pred = lm1.predict(d)\n",
    "    conf = confusion_matrix(pred, d_lab)\n",
    "    print(conf)\n",
    "    \n",
    "    if score1 > max1:\n",
    "        max1 = score1\n",
    "        c1 = c\n",
    "    if score2 > max2:\n",
    "        max2 = score2\n",
    "        c2 = c\n",
    "    \n",
    "print(\"\\nBest L1 c:\", c1, \"score:\", max1)\n",
    "print(\"Best L2 c:\", c2, \"score:\", max2)\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running through Test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'NDF': 0, 'US': 1, 'non-US': 2}\n"
     ]
    }
   ],
   "source": [
    "# Use L1 regularization with c=1\n",
    "\n",
    "te.shape\n",
    "lm = LogisticRegression(C = c1, penalty = \"l1\")\n",
    "lm.fit(tr, t_lab)\n",
    "preds = lm.predict(te)\n",
    "preds\n",
    "\n",
    "country_code = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(country_code)\n",
    "\n",
    "countries = []\n",
    "for i in preds:\n",
    "    if i == 0:\n",
    "        pred = 'NDF'\n",
    "    elif i == 1:\n",
    "        pred = 'US'\n",
    "    else:\n",
    "        pred = 'other'\n",
    "    countries.append(pred)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create dataframe and write to csv\n",
    "ids = list(data.id[test_cutoff:])\n",
    "logreg_sub = pd.DataFrame({'id': ids, 'country': countries}, columns=['id', 'country'])\n",
    "\n",
    "logreg_sub.to_csv('./logreg_submission.csv',sep=',', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
