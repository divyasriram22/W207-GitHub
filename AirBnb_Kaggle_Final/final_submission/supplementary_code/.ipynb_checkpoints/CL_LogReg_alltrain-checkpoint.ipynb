{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giles/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/giles/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# General libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Draw inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set_context(\"notebook\", font_scale=1.5)\n",
    "\n",
    "# Sklearn preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Sklearn libraries.\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giles/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (213451, 541)\n",
      "test shape: (62096, 540)\n"
     ]
    }
   ],
   "source": [
    "# Load full data set (combined with actions)\n",
    "train = pd.read_csv('../data/train_combined_actions.zip')\n",
    "print(\"train shape:\", train.shape)\n",
    "\n",
    "# load test data\n",
    "test = pd.read_csv('../data/test_combined_actions.zip')\n",
    "print(\"test shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full dataset shape: (275547, 26)\n",
      "dev labels shape (25000,)\n",
      "train_labels shape (188451,)\n",
      "features: ['id', 'date_account_created', 'timestamp_first_active', 'gender', 'age', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser', 'month_created', 'season_created', 'year_created', 'bin_age', 'bin_lang', 'days_since_creation', 'first_hour', 'count_actions', 'number_devices', 'longest_session', 'total_time', 'last_action']\n"
     ]
    }
   ],
   "source": [
    "train = train.reset_index().iloc[: , 1:]\n",
    "\n",
    "# Shuffle training set\n",
    "shuffle = np.random.permutation(np.arange(train.shape[0]))\n",
    "train = train.reindex(shuffle)\n",
    "\n",
    "# Split labels from training set\n",
    "train_labels = train['country_destination']\n",
    "train_data = train.drop('country_destination', axis=1)\n",
    "\n",
    "# Concatenate test data (so able to binarize categorical features later)\n",
    "data = pd.concat((train_data, test))\n",
    "\n",
    "# remove action features\n",
    "col = data.columns.get_loc(\"last_action\") # last column index before action columns begin\n",
    "data = data.iloc[: , :col+1]\n",
    "\n",
    "# Define row index on where to split full dataset for dev, train, and test\n",
    "dev_cutoff = 25000   # 12% of training data\n",
    "test_cutoff = train.shape[0]\n",
    "\n",
    "dev_labels, train_labels = train_labels[:25000], train_labels[25000:]\n",
    "\n",
    "print(\"full dataset shape:\", data.shape)\n",
    "print(\"dev labels shape\", dev_labels.shape)\n",
    "print(\"train_labels shape\", train_labels.shape)\n",
    "print(\"features:\", list(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188451,)\n",
      "(25000,)\n",
      "{'NDF': 0, 'US': 1, 'non-US': 2}\n"
     ]
    }
   ],
   "source": [
    "# Output 3 classes: NDF, US, Non-US\n",
    "def country(col):\n",
    "    if col == 'NDF':\n",
    "        return \"NDF\"\n",
    "    elif col == 'US':\n",
    "        return 'US'\n",
    "    else:\n",
    "        return 'non-US'\n",
    "    \n",
    "t = train_labels.apply(country)\n",
    "d = dev_labels.apply(country)\n",
    "\n",
    "# Convert labels to numeric\n",
    "le = preprocessing.LabelEncoder() # Initialize label_encoder\n",
    "t_lab, d_lab = le.fit_transform(t), le.fit_transform(d)\n",
    "\n",
    "print(t_lab.shape)\n",
    "print(d_lab.shape)\n",
    "\n",
    "country_code = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(country_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating through features using Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Feature: bin_age\n",
      "L1 num cols:  5 score: 0.58604\n",
      "L2 num cols:  5 score: 0.58604\n",
      "[[14651  7272  3077]\n",
      " [    0     0     0]\n",
      " [    0     0     0]]\n",
      "\n",
      "Added Feature: first_browser\n",
      "L1 num cols:  60 score: 0.58764\n",
      "L2 num cols:  60 score: 0.58764\n",
      "[[12963  5543  2385]\n",
      " [ 1688  1728   692]\n",
      " [    0     1     0]]\n",
      "\n",
      "Added Feature: gender\n",
      "L1 num cols:  64 score: 0.59548\n",
      "L2 num cols:  64 score: 0.59548\n",
      "[[12871  5255  2262]\n",
      " [ 1780  2016   815]\n",
      " [    0     1     0]]\n",
      "\n",
      "Added Feature: signup_method\n",
      "L1 num cols:  68 score: 0.62764\n",
      "L2 num cols:  68 score: 0.62764\n",
      "[[12518  4098  1789]\n",
      " [ 2133  3173  1288]\n",
      " [    0     1     0]]\n",
      "\n",
      "Added Feature: last_action\n",
      "L1 num cols:  200 score: 0.63364\n",
      "L2 num cols:  200 score: 0.63364\n",
      "[[12595  4024  1772]\n",
      " [ 2056  3246  1305]\n",
      " [    0     2     0]]\n",
      "\n",
      "Added Feature: season_created\n",
      "L1 num cols:  204 score: 0.6324\n",
      "L2 num cols:  204 score: 0.6324\n",
      "[[12609  4069  1786]\n",
      " [ 2042  3201  1291]\n",
      " [    0     2     0]]\n",
      "\n",
      "Added Feature: first_device_type\n",
      "L1 num cols:  213 score: 0.63204\n",
      "L2 num cols:  213 score: 0.63204\n",
      "[[12616  4085  1777]\n",
      " [ 2034  3185  1300]\n",
      " [    1     2     0]]\n",
      "\n",
      "Added Feature: signup_app\n",
      "L1 num cols:  217 score: 0.63196\n",
      "L2 num cols:  217 score: 0.63196\n",
      "[[12636  4107  1794]\n",
      " [ 2014  3163  1283]\n",
      " [    1     2     0]]\n",
      "\n",
      "Added Feature: affiliate_channel\n",
      "L1 num cols:  225 score: 0.63356\n",
      "L2 num cols:  225 score: 0.63344\n",
      "[[12649  4083  1790]\n",
      " [ 2001  3187  1287]\n",
      " [    1     2     0]]\n",
      "\n",
      "Added Feature: first_hour\n",
      "L1 num cols:  249 score: 0.63424\n",
      "L2 num cols:  249 score: 0.63424\n",
      "[[12655  4069  1792]\n",
      " [ 1986  3196  1280]\n",
      " [   10     7     5]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giles/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:69: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/giles/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:70: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/giles/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:71: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Added Feature: count_actions\n",
      "L1 num cols:  250 score: 0.63396\n",
      "L2 num cols:  250 score: 0.63384\n",
      "[[12652  4078  1787]\n",
      " [ 1987  3187  1283]\n",
      " [   12     7     7]]\n",
      "\n",
      "Added Feature: days_since_creation\n",
      "L1 num cols:  251 score: 0.63512\n",
      "L2 num cols:  251 score: 0.63484\n",
      "[[12676  4076  1789]\n",
      " [ 1965  3189  1282]\n",
      " [   10     7     6]]\n",
      "\n",
      "Added Feature: total_time\n",
      "L1 num cols:  252 score: 0.6356\n",
      "L2 num cols:  252 score: 0.58604\n",
      "[[14651  7272  3077]\n",
      " [    0     0     0]\n",
      " [    0     0     0]]\n",
      "\n",
      "Added Feature: number_devices\n",
      "L1 num cols:  253 score: 0.63496\n",
      "L2 num cols:  253 score: 0.58604\n",
      "[[14651  7272  3077]\n",
      " [    0     0     0]\n",
      " [    0     0     0]]\n",
      "\n",
      "Added Feature: longest_session\n",
      "L1 num cols:  254 score: 0.63544\n",
      "L2 num cols:  254 score: 0.58604\n",
      "[[14651  7272  3077]\n",
      " [    0     0     0]\n",
      " [    0     0     0]]\n"
     ]
    }
   ],
   "source": [
    "def binarize(data, devcut, testcut, column): \n",
    "    dev_bin = pd.get_dummies(data[column])[:devcut]\n",
    "    train_bin = pd.get_dummies(data[column])[devcut:testcut]\n",
    "    test_bin = pd.get_dummies(data[column])[testcut:]\n",
    "    return dev_bin, train_bin, test_bin\n",
    "\n",
    "def logreg(c, penalty, train, train_label, dev, dev_label):\n",
    "    lm = LogisticRegression(C = c, penalty = penalty)\n",
    "    lm.fit(tr, t_lab)\n",
    "    score = lm.score(d, d_lab)\n",
    "    return lm, score\n",
    "\n",
    "# cat_feat = ['bin_age', 'first_browser', 'gender', 'signup_method', 'last_action']\n",
    "\n",
    "cat_feat = ['bin_age', 'first_browser', 'gender', 'signup_method', 'last_action', \n",
    "            'season_created', 'first_device_type', 'signup_app', 'affiliate_channel', 'first_hour']\n",
    "\n",
    "# Initialize with first feature column \n",
    "d, tr, te = binarize(data, dev_cutoff, test_cutoff, cat_feat[0])\n",
    "\n",
    "print(\"First Feature:\", cat_feat[0])\n",
    "lm1, score1 = logreg(50, \"l1\", tr, t_lab, d, d_lab) # Run logreg with l1 penalty\n",
    "print(\"L1 num cols: \", tr.shape[1], \"score:\", score1)\n",
    "\n",
    "lm2, score2 = logreg(50, \"l2\", tr, t_lab, d, d_lab) # Run logreg with l2 penalty\n",
    "print(\"L2 num cols: \", tr.shape[1], \"score:\", score2)\n",
    "\n",
    "pred = lm2.predict(d)\n",
    "conf = confusion_matrix(pred, d_lab)\n",
    "print(conf)\n",
    "\n",
    "d2, tr2, te2 = binarize(data, dev_cutoff, test_cutoff, cat_feat[2])\n",
    "\n",
    "# Binarize categorical features, add to dataset, run logistic regression on binarized features\n",
    "for x in cat_feat[1:]:\n",
    "    d_bin, tr_bin, te_bin = binarize(data, dev_cutoff, test_cutoff, x)\n",
    "    d = np.concatenate((d, d_bin), axis=1)\n",
    "    tr = np.concatenate((tr, tr_bin), axis=1)\n",
    "    te = np.concatenate((te, te_bin), axis=1)\n",
    "\n",
    "    # Run logistic regression on data set with added feature\n",
    "    print(\"\\nAdded Feature:\", x)\n",
    "    lm1, score1 = logreg(50, \"l1\", tr, t_lab, d, d_lab)\n",
    "    print(\"L1 num cols: \", tr.shape[1], \"score:\", score1)\n",
    "    lm2, score2 = logreg(50, \"l2\", tr, t_lab, d, d_lab)\n",
    "    print(\"L2 num cols: \", tr.shape[1], \"score:\", score2)\n",
    "\n",
    "    pred = lm2.predict(d)\n",
    "    conf = confusion_matrix(pred, d_lab)\n",
    "    print(conf)\n",
    "\n",
    "# Iterate over numerical features\n",
    "num_feat = ['count_actions', 'days_since_creation', 'total_time', \n",
    "            'number_devices', 'longest_session']\n",
    "# num_feat = ['count_actions']\n",
    "\n",
    "# underperforming numerical features:\n",
    "# 'days_since_creation', 'total_time', 'number_devices', 'longest_session', 'request_photography'\n",
    "\n",
    "\n",
    "for y in num_feat:\n",
    "    # get column and fill in NaNs with training data column mean\n",
    "    mean = np.mean(data[y][dev_cutoff:test_cutoff])\n",
    "    \n",
    "    tr_col = data[y][dev_cutoff:test_cutoff].fillna(mean)\n",
    "    d_col = data[y][:dev_cutoff].fillna(mean)\n",
    "    te_col = data[y][test_cutoff:].fillna(mean)\n",
    "    \n",
    "    tr_col = tr_col.reshape(tr.shape[0], 1)\n",
    "    d_col = d_col.reshape(d.shape[0], 1)\n",
    "    te_col = te_col.reshape(te.shape[0], 1)\n",
    "    \n",
    "    # add column to previous training set\n",
    "    tr = np.concatenate((tr, tr_col), axis=1)\n",
    "    d = np.concatenate((d, d_col), axis=1)\n",
    "    te = np.concatenate((te, te_col), axis=1)\n",
    "\n",
    "    # Run logistic regression on data set with added feature\n",
    "    print(\"\\nAdded Feature:\", y)\n",
    "    lm1, score1 = logreg(50, \"l1\", tr, t_lab, d, d_lab)\n",
    "    print(\"L1 num cols: \", tr.shape[1], \"score:\", score1)\n",
    "    lm2, score2 = logreg(50, \"l2\", tr, t_lab, d, d_lab)\n",
    "    print(\"L2 num cols: \", tr.shape[1], \"score:\", score2)\n",
    "\n",
    "    pred = lm2.predict(d)\n",
    "    conf = confusion_matrix(pred, d_lab)\n",
    "    print(conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L1 num cols:  254,  C: 0.5,  score: 0.6354\n",
      "L2 num cols:  254,  C: 0.5,  score: 0.5860\n",
      "[[12707  4089  1802]\n",
      " [ 1933  3176  1272]\n",
      " [   11     7     3]]\n",
      "\n",
      "L1 num cols:  254,  C:  1,  score: 0.6352\n",
      "L2 num cols:  254,  C:  1,  score: 0.5860\n",
      "[[12702  4090  1803]\n",
      " [ 1938  3175  1271]\n",
      " [   11     7     3]]\n",
      "\n",
      "L1 num cols:  254,  C: 10,  score: 0.6352\n",
      "L2 num cols:  254,  C: 10,  score: 0.5860\n",
      "[[12701  4088  1803]\n",
      " [ 1938  3176  1270]\n",
      " [   12     8     4]]\n",
      "\n",
      "L1 num cols:  254,  C: 50,  score: 0.6352\n",
      "L2 num cols:  254,  C: 50,  score: 0.5860\n",
      "[[12700  4087  1803]\n",
      " [ 1939  3176  1270]\n",
      " [   12     9     4]]\n",
      "\n",
      "L1 num cols:  254,  C: 100,  score: 0.6353\n",
      "L2 num cols:  254,  C: 100,  score: 0.5860\n",
      "[[12704  4088  1802]\n",
      " [ 1935  3175  1271]\n",
      " [   12     9     4]]\n",
      "\n",
      "Best L1 c: 0.5 score: 0.63544\n",
      "Best L2 c: 0.5 score: 0.58604\n"
     ]
    }
   ],
   "source": [
    "# Run last model and iterate over Cs\n",
    "Cs = [0.5, 1, 10, 50, 100]\n",
    "\n",
    "max1, max2 = 0, 0\n",
    "c1, c2 = 0, 0\n",
    "\n",
    "for c in Cs: \n",
    "    lm1, score1 = logreg(c, \"l1\", tr, t_lab, d, d_lab)\n",
    "    print(\"\\nL1 num cols: %4s,  C: %2s,  score: %.4f\" %(tr.shape[1], c, score1))\n",
    "    \n",
    "    lm2, score2 = logreg(c, \"l2\", tr, t_lab, d, d_lab)\n",
    "    print(\"L2 num cols: %4s,  C: %2s,  score: %.4f\" %(tr.shape[1], c, score2))\n",
    "\n",
    "    pred = lm1.predict(d)\n",
    "    conf = confusion_matrix(pred, d_lab)\n",
    "    print(conf)\n",
    "    \n",
    "    if score1 > max1:\n",
    "        max1 = score1\n",
    "        c1 = c\n",
    "    if score2 > max2:\n",
    "        max2 = score2\n",
    "        c2 = c\n",
    "    \n",
    "print(\"\\nBest L1 c:\", c1, \"score:\", max1)\n",
    "print(\"Best L2 c:\", c2, \"score:\", max2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
