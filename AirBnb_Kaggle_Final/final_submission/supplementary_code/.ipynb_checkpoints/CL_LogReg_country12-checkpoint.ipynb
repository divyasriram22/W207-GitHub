{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giles/anaconda/lib/python3.6/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/giles/anaconda/lib/python3.6/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# General libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "# Draw inline\n",
    "%matplotlib inline\n",
    "\n",
    "# Set seaborn style\n",
    "sns.set_context(\"notebook\", font_scale=1.5)\n",
    "\n",
    "# Sklearn preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "# Sklearn libraries.\n",
    "from sklearn import linear_model\n",
    "from sklearn import preprocessing\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giles/anaconda/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2717: DtypeWarning: Columns (26) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape: (213451, 541)\n",
      "test shape: (62096, 540)\n"
     ]
    }
   ],
   "source": [
    "# Load full data set (combined with actions)\n",
    "train = pd.read_csv('../data/train_combined_actions.zip')\n",
    "print(\"train shape:\", train.shape)\n",
    "\n",
    "# load test data\n",
    "test = pd.read_csv('../data/test_combined_actions.zip')\n",
    "print(\"test shape:\", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "full dataset shape: (135911, 26)\n",
      "dev labels shape (8850,)\n",
      "train_labels shape (64965,)\n",
      "features: ['id', 'date_account_created', 'timestamp_first_active', 'gender', 'age', 'signup_method', 'signup_flow', 'language', 'affiliate_channel', 'affiliate_provider', 'first_affiliate_tracked', 'signup_app', 'first_device_type', 'first_browser', 'month_created', 'season_created', 'year_created', 'bin_age', 'bin_lang', 'days_since_creation', 'first_hour', 'count_actions', 'number_devices', 'longest_session', 'total_time', 'last_action']\n"
     ]
    }
   ],
   "source": [
    "# subset full data set to only include users that have sessions data, remove action counts for now \n",
    "mod_train = train[train.count_actions.isnull() != True]\n",
    "mod_train = mod_train.reset_index().iloc[: , 1:]\n",
    "\n",
    "# Shuffle training set\n",
    "shuffle = np.random.permutation(np.arange(mod_train.shape[0]))\n",
    "mod_train = mod_train.reindex(shuffle)\n",
    "\n",
    "# Split labels from training set\n",
    "train_labels = mod_train['country_destination']\n",
    "train_data = mod_train.drop('country_destination', axis=1)\n",
    "\n",
    "# Concatenate test data (so able to binarize categorical features later)\n",
    "data = pd.concat((train_data, test))\n",
    "\n",
    "# remove action features\n",
    "col = data.columns.get_loc(\"last_action\") # last column index before action columns begin\n",
    "data = data.iloc[: , :col+1]\n",
    "\n",
    "# Define row index on where to split full dataset for dev, train, and test\n",
    "dev_cutoff = 8850   # 12% of training data\n",
    "test_cutoff = mod_train.shape[0]\n",
    "\n",
    "dev_labels, train_labels = train_labels[:8850], train_labels[8850:]\n",
    "\n",
    "print(\"full dataset shape:\", data.shape)\n",
    "print(\"dev labels shape\", dev_labels.shape)\n",
    "print(\"train_labels shape\", train_labels.shape)\n",
    "print(\"features:\", list(data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(64965,)\n",
      "(8850,)\n",
      "{'AU': 0, 'CA': 1, 'DE': 2, 'ES': 3, 'FR': 4, 'GB': 5, 'IT': 6, 'NDF': 7, 'NL': 8, 'PT': 9, 'US': 10, 'other': 11}\n"
     ]
    }
   ],
   "source": [
    "# Convert labels to numeric\n",
    "le = preprocessing.LabelEncoder() # Initialize label_encoder\n",
    "t_lab, d_lab = le.fit_transform(train_labels), le.fit_transform(dev_labels)\n",
    "\n",
    "print(t_lab.shape)\n",
    "print(d_lab.shape)\n",
    "\n",
    "country_code = dict(zip(le.classes_, le.transform(le.classes_)))\n",
    "print(country_code)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iterating through features using Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Feature: bin_age\n",
      "L1 num cols:  5 score: 0.602824858757\n",
      "L2 num cols:  5 score: 0.602824858757\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [  11   52   27   96  181   87  131 5335   30   12 2455  433]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Added Feature: first_browser\n",
      "L1 num cols:  45 score: 0.610847457627\n",
      "L2 num cols:  45 score: 0.610847457627\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    1    0    0    0    0]\n",
      " [   5   30   13   64  112   62   89 4380   15    9 1429  265]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   6   22   14   32   69   25   42  954   15    3 1026  168]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Added Feature: gender\n",
      "L1 num cols:  49 score: 0.620677966102\n",
      "L2 num cols:  49 score: 0.620790960452\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    1    0    0    0    0]\n",
      " [   8   34   15   70  133   70  105 4728   20   10 1689  289]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   3   18   12   26   48   17   26  606   10    2  766  144]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Added Feature: signup_method\n",
      "L1 num cols:  53 score: 0.656271186441\n",
      "L2 num cols:  53 score: 0.656271186441\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   4   30   16   53   88   53   77 4583   14    7 1230  236]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   7   22   11   43   93   34   54  752   16    5 1225  197]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Added Feature: last_action\n",
      "L1 num cols:  185 score: 0.664858757062\n",
      "L2 num cols:  185 score: 0.664858757062\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   5   26   14   52   91   53   75 4620   12    6 1191  236]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   6   26   13   44   90   34   56  715   18    6 1264  197]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Added Feature: count_actions\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/giles/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:70: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/giles/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:71: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n",
      "/Users/giles/anaconda/lib/python3.6/site-packages/ipykernel/__main__.py:72: FutureWarning: reshape is deprecated and will raise in a subsequent release. Please use .values.reshape(...) instead\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "L1 num cols:  186 score: 0.664745762712\n",
      "L2 num cols:  186 score: 0.665197740113\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   5   27   14   52   93   52   74 4621   12    6 1189  236]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   6   25   13   44   88   35   57  714   18    6 1266  197]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "529.9591269493103\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "start = time.time()\n",
    "\n",
    "def binarize(data, devcut, testcut, column): \n",
    "    dev_bin = pd.get_dummies(data[column])[:devcut]\n",
    "    train_bin = pd.get_dummies(data[column])[devcut:testcut]\n",
    "    test_bin = pd.get_dummies(data[column])[testcut:]\n",
    "    return dev_bin, train_bin, test_bin\n",
    "\n",
    "def logreg(c, penalty, train, train_label, dev, dev_label):\n",
    "    lm = LogisticRegression(C = c, penalty = penalty)\n",
    "    lm.fit(tr, t_lab)\n",
    "    score = lm.score(d, d_lab)\n",
    "    return lm, score\n",
    "    \n",
    "cat_feat = ['bin_age', 'first_browser', 'gender', 'signup_method', 'last_action']\n",
    "\n",
    "# underperforming categorical variables: \n",
    "# 'season_created', 'first_device_type', signup_app', 'affiliate_channel', 'first_hour'\n",
    "\n",
    "# Initialize with first feature column \n",
    "d, tr, te = binarize(data, dev_cutoff, test_cutoff, cat_feat[0])\n",
    "\n",
    "print(\"First Feature:\", cat_feat[0])\n",
    "lm1, score1 = logreg(50, \"l1\", tr, t_lab, d, d_lab) # Run logreg with l1 penalty\n",
    "print(\"L1 num cols: \", tr.shape[1], \"score:\", score1)\n",
    "\n",
    "lm2, score2 = logreg(50, \"l2\", tr, t_lab, d, d_lab) # Run logreg with l2 penalty\n",
    "print(\"L2 num cols: \", tr.shape[1], \"score:\", score2)\n",
    "\n",
    "pred = lm2.predict(d)\n",
    "conf = confusion_matrix(pred, d_lab)\n",
    "print(conf)\n",
    "\n",
    "d2, tr2, te2 = binarize(data, dev_cutoff, test_cutoff, cat_feat[2])\n",
    "\n",
    "# Binarize categorical features, add to dataset, run logistic regression on binarized features\n",
    "for x in cat_feat[1:]:\n",
    "    d_bin, tr_bin, te_bin = binarize(data, dev_cutoff, test_cutoff, x)\n",
    "    d = np.concatenate((d, d_bin), axis=1)\n",
    "    tr = np.concatenate((tr, tr_bin), axis=1)\n",
    "    te = np.concatenate((te, te_bin), axis=1)\n",
    "\n",
    "    # Run logistic regression on data set with added feature\n",
    "    print(\"\\nAdded Feature:\", x)\n",
    "    lm1, score1 = logreg(50, \"l1\", tr, t_lab, d, d_lab)\n",
    "    print(\"L1 num cols: \", tr.shape[1], \"score:\", score1)\n",
    "    lm2, score2 = logreg(50, \"l2\", tr, t_lab, d, d_lab)\n",
    "    print(\"L2 num cols: \", tr.shape[1], \"score:\", score2)\n",
    "\n",
    "    pred = lm2.predict(d)\n",
    "    conf = confusion_matrix(pred, d_lab)\n",
    "    print(conf)\n",
    "\n",
    "# Iterate over numerical features\n",
    "num_feat = ['count_actions']\n",
    "\n",
    "# underperforming numerical features:\n",
    "# 'days_since_creation', 'total_time', 'number_devices', 'longest_session', 'request_photography'\n",
    "\n",
    "num_feat = ['count_actions']\n",
    "for y in num_feat:\n",
    "    # get column and fill in NaNs with training data column mean\n",
    "    mean = np.mean(data[y][dev_cutoff:test_cutoff])\n",
    "    \n",
    "    tr_col = data[y][dev_cutoff:test_cutoff].fillna(mean)\n",
    "    d_col = data[y][:dev_cutoff].fillna(mean)\n",
    "    te_col = data[y][test_cutoff:].fillna(mean)\n",
    "    \n",
    "    tr_col = tr_col.reshape(tr.shape[0], 1)\n",
    "    d_col = d_col.reshape(d.shape[0], 1)\n",
    "    te_col = te_col.reshape(te.shape[0], 1)\n",
    "    \n",
    "    # add column to previous training set\n",
    "    tr = np.concatenate((tr, tr_col), axis=1)\n",
    "    d = np.concatenate((d, d_col), axis=1)\n",
    "    te = np.concatenate((te, te_col), axis=1)\n",
    "\n",
    "    # Run logistic regression on data set with added feature\n",
    "    print(\"\\nAdded Feature:\", y)\n",
    "    lm1, score1 = logreg(50, \"l1\", tr, t_lab, d, d_lab)\n",
    "    print(\"L1 num cols: \", tr.shape[1], \"score:\", score1)\n",
    "    lm2, score2 = logreg(50, \"l2\", tr, t_lab, d, d_lab)\n",
    "    print(\"L2 num cols: \", tr.shape[1], \"score:\", score2)\n",
    "\n",
    "    pred = lm2.predict(d)\n",
    "    conf = confusion_matrix(pred, d_lab)\n",
    "    print(conf)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "L1 num cols:  186,  C: 0.5,  score: 0.6651\n",
      "L2 num cols:  186,  C: 0.5,  score: 0.6656\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   5   27   13   52   90   52   74 4621   12    6 1190  233]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   6   25   14   44   91   35   57  714   18    6 1265  200]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "L1 num cols:  186,  C:  1,  score: 0.6650\n",
      "L2 num cols:  186,  C:  1,  score: 0.6658\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   5   26   13   52   91   52   74 4621   12    6 1191  234]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   6   26   14   44   90   35   57  714   18    6 1264  199]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "L1 num cols:  186,  C: 10,  score: 0.6650\n",
      "L2 num cols:  186,  C: 10,  score: 0.6649\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   5   26   14   52   91   52   74 4619   12    6 1189  235]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   6   26   13   44   90   35   57  716   18    6 1266  198]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "L1 num cols:  186,  C: 50,  score: 0.6649\n",
      "L2 num cols:  186,  C: 50,  score: 0.6652\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   5   26   14   52   91   52   74 4619   12    6 1190  235]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   6   26   13   44   90   35   57  716   18    6 1265  198]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "L1 num cols:  186,  C: 100,  score: 0.6649\n",
      "L2 num cols:  186,  C: 100,  score: 0.6647\n",
      "[[   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   5   26   14   52   91   52   74 4619   12    6 1190  235]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]\n",
      " [   6   26   13   44   90   35   57  716   18    6 1265  198]\n",
      " [   0    0    0    0    0    0    0    0    0    0    0    0]]\n",
      "\n",
      "Best L1 c: 0.5 score: 0.665084745763\n",
      "Best L2 c: 1 score: 0.665762711864\n",
      "158.80300211906433\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "# Run last model and iterate over Cs\n",
    "Cs = [0.5, 1, 10, 50, 100]\n",
    "\n",
    "max1, max2 = 0, 0\n",
    "c1, c2 = 0, 0\n",
    "\n",
    "for c in Cs: \n",
    "    lm1, score1 = logreg(c, \"l1\", tr, t_lab, d, d_lab)\n",
    "    print(\"\\nL1 num cols: %4s,  C: %2s,  score: %.4f\" %(tr.shape[1], c, score1))\n",
    "    \n",
    "    lm2, score2 = logreg(c, \"l2\", tr, t_lab, d, d_lab)\n",
    "    print(\"L2 num cols: %4s,  C: %2s,  score: %.4f\" %(tr.shape[1], c, score2))\n",
    "\n",
    "    pred = lm1.predict(d)\n",
    "    conf = confusion_matrix(pred, d_lab)\n",
    "    print(conf)\n",
    "    \n",
    "    if score1 > max1:\n",
    "        max1 = score1\n",
    "        c1 = c\n",
    "    if score2 > max2:\n",
    "        max2 = score2\n",
    "        c2 = c\n",
    "    \n",
    "print(\"\\nBest L1 c:\", c1, \"score:\", max1)\n",
    "print(\"Best L2 c:\", c2, \"score:\", max2)\n",
    "\n",
    "end = time.time()\n",
    "print(end - start)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
