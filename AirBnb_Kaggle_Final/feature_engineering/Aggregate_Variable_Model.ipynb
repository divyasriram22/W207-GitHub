{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divyas/anaconda/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/divyas/anaconda/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn library for preprocessing\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# Set the randomizer seed so results are the same each time.\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Read in csv and create arrays\n",
    "users_train_raw = pd.read_csv('../zip_files/train_users_2.csv.zip')\n",
    "sessions_raw = pd.read_csv('../zip_files/sessions.csv.zip')\n",
    "demographics = pd.read_csv('../zip_files/age_gender_bkts.csv.zip')\n",
    "countries = pd.read_csv('../zip_files/countries.csv.zip')\n",
    "test = pd.read_csv('../zip_files/test_users.csv.zip')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/divyas/anaconda/lib/python2.7/site-packages/sklearn/utils/validation.py:429: DataConversionWarning: Data with input dtype int64 was converted to float64 by the normalize function.\n",
      "  warnings.warn(msg, _DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Shuffle data\n",
    "np.random.seed(0)\n",
    "shuffle = np.random.permutation(np.arange(users_train_raw.shape[0]))\n",
    "len(shuffle)\n",
    "x = users_train_raw.reindex(shuffle).ix[:,1:] # remove user_id\n",
    "\n",
    "# encode all values in numbers \n",
    "y = pd.DataFrame()\n",
    "for column in list(x):\n",
    "    y[column] = pd.factorize(x[column], sort=True)[0]\n",
    "\n",
    "# split out labels from features\n",
    "# normalize features\n",
    "data, labels = preprocessing.normalize(np.asarray(y)[:,:-1]), np.asarray(y)[:,-1]\n",
    "\n",
    "# Split into train and dev.\n",
    "dev_data, dev_labels = data[:25000], labels[:25000]\n",
    "train_data, train_labels = data[25000:], labels[25000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# MODEL WITHOUT SIGNUP_FLOW VARIABLE\n",
    "\n",
    "train = pd.read_csv('../train_dev_data/train_data.csv')\n",
    "dev = pd.read_csv('../train_dev_data/dev_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#CREATING A SMALLER DATA SET\n",
    "\n",
    "small_train = train[:10000]\n",
    "small_dev = dev[:10000]\n",
    "small_train_labels = train_labels[:10000]\n",
    "small_dev_labels = dev_labels[:10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_-unknown-</th>\n",
       "      <th>gender_FEMALE</th>\n",
       "      <th>gender_MALE</th>\n",
       "      <th>gender_OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender_-unknown-  gender_FEMALE  gender_MALE  gender_OTHER\n",
       "0                 1              0            0             0\n",
       "1                 0              1            0             0\n",
       "2                 1              0            0             0\n",
       "3                 1              0            0             0\n",
       "4                 0              1            0             0"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#variables = ['id', 'date_first_booking', 'gender', 'signup_method', 'language', 'signup_flow', 'affiliate_channel', 'affiliate_provider', 'signup_app', 'first_device_type', 'first_browser']\n",
    "#variables = ['id', 'date_first_booking', 'gender', 'language', 'first_device_type', 'first_browser']\n",
    "variables = ['gender']\n",
    "\n",
    "train_variables_data = pd.get_dummies(small_train[['gender']], columns=variables)\n",
    "train_variables_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>gender_-unknown-</th>\n",
       "      <th>gender_FEMALE</th>\n",
       "      <th>gender_MALE</th>\n",
       "      <th>gender_OTHER</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   gender_-unknown-  gender_FEMALE  gender_MALE  gender_OTHER\n",
       "0                 0              0            1             0\n",
       "1                 0              1            0             0\n",
       "2                 1              0            0             0\n",
       "3                 1              0            0             0\n",
       "4                 0              1            0             0"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_variables_data = pd.get_dummies(small_dev[['gender']], columns=variables)\n",
    "dev_variables_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convert that dataframe back into an array to test the model\n",
    "train_variables_array = np.array(train_variables_data)\n",
    "dev_variables_array = np.array(dev_variables_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(188451, 14)\n",
      "(25000, 14)\n",
      "--------\n",
      "(50000, 16)\n",
      "(25000, 16)\n",
      "(50000,)\n",
      "(25000,)\n",
      "--------\n",
      "(50000, 4)\n",
      "(25000, 4)\n"
     ]
    }
   ],
   "source": [
    "print((train_data.shape))\n",
    "print((dev_data.shape))\n",
    "print \"--------\"\n",
    "print((small_train.shape))\n",
    "print((small_dev.shape))\n",
    "print((small_train_labels.shape))\n",
    "print((small_dev_labels.shape))\n",
    "print \"--------\"\n",
    "print((train_variables_array.shape))\n",
    "print((dev_variables_array.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GENDER    ||    Best Accuracy: __0.59____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.000000  dev accuracy: 0.00\n",
      "alpha: 0.000100  dev accuracy: 0.59\n",
      "alpha: 0.001000  dev accuracy: 0.59\n",
      "alpha: 0.010000  dev accuracy: 0.59\n",
      "alpha: 0.100000  dev accuracy: 0.59\n",
      "alpha: 0.500000  dev accuracy: 0.59\n",
      "alpha: 1.000000  dev accuracy: 0.59\n",
      "alpha: 2.000000  dev accuracy: 0.59\n",
      "alpha: 10.000000  dev accuracy: 0.59\n"
     ]
    }
   ],
   "source": [
    "variables = ['gender']\n",
    "\n",
    "train_variables_data = pd.get_dummies(small_train[['gender']], columns=variables)\n",
    "dev_variables_data = pd.get_dummies(small_dev[['gender']], columns=variables)\n",
    "\n",
    "#convert that dataframe back into an array to test the model\n",
    "train_variables_array = np.array(train_variables_data)\n",
    "dev_variables_array = np.array(dev_variables_data)\n",
    "\n",
    "alphas = {'alpha': [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "\n",
    "for alpha in alphas.get(\"alpha\"):\n",
    "    bnb = BernoulliNB(alpha = alpha)\n",
    "    bnb.fit(train_variables_data, small_train_labels)\n",
    "    score = bnb.score(dev_variables_data, small_dev_labels)\n",
    "    print(\"alpha: %f  dev accuracy: %.2f\" %(alpha, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### AGE    ||    Best Accuracy: __????____"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Expected input with 110 features, got 104 instead",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-71f81b32bfae>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mbnb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBernoulliNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mbnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_variables_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmall_train_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbnb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_variables_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msmall_dev_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     16\u001b[0m     \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"alpha: %f  dev accuracy: %.2f\"\u001b[0m \u001b[0;34m%\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/divyas/anaconda/lib/python2.7/site-packages/sklearn/base.pyc\u001b[0m in \u001b[0;36mscore\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    347\u001b[0m         \"\"\"\n\u001b[1;32m    348\u001b[0m         \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 349\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    350\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    351\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/divyas/anaconda/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m     63\u001b[0m             \u001b[0mPredicted\u001b[0m \u001b[0mtarget\u001b[0m \u001b[0mvalues\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \"\"\"\n\u001b[0;32m---> 65\u001b[0;31m         \u001b[0mjll\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_joint_log_likelihood\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjll\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/divyas/anaconda/lib/python2.7/site-packages/sklearn/naive_bayes.pyc\u001b[0m in \u001b[0;36m_joint_log_likelihood\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    816\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_features_X\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m             raise ValueError(\"Expected input with %d features, got %d instead\"\n\u001b[0;32m--> 818\u001b[0;31m                              % (n_features, n_features_X))\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m         \u001b[0mneg_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeature_log_prob_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Expected input with 110 features, got 104 instead"
     ]
    }
   ],
   "source": [
    "variables = ['age']\n",
    "\n",
    "train_variables_data = pd.get_dummies(small_train[['age']], columns=variables)\n",
    "dev_variables_data = pd.get_dummies(small_dev[['age']], columns=variables)\n",
    "\n",
    "#convert that dataframe back into an array to test the model\n",
    "train_variables_array = np.array(train_variables_data)\n",
    "dev_variables_array = np.array(dev_variables_data)\n",
    "\n",
    "alphas = {'alpha': [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "\n",
    "for alpha in alphas.get(\"alpha\"):\n",
    "    bnb = BernoulliNB(alpha = alpha)\n",
    "    bnb.fit(train_variables_data, small_train_labels)\n",
    "    score = bnb.score(dev_variables_data, small_dev_labels)\n",
    "    print(\"alpha: %f  dev accuracy: %.2f\" %(alpha, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CENDY'S MODEL WITH ALL VARIABLES || Best Accuracy: 0.88"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha: 0.000000  dev accuracy: 0.00\n",
      "alpha: 0.000100  dev accuracy: 0.88\n",
      "alpha: 0.001000  dev accuracy: 0.88\n",
      "alpha: 0.010000  dev accuracy: 0.88\n",
      "alpha: 0.100000  dev accuracy: 0.88\n",
      "alpha: 0.500000  dev accuracy: 0.88\n",
      "alpha: 1.000000  dev accuracy: 0.88\n",
      "alpha: 2.000000  dev accuracy: 0.88\n",
      "alpha: 10.000000  dev accuracy: 0.88\n"
     ]
    }
   ],
   "source": [
    "alphas = {'alpha': [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0]}\n",
    "\n",
    "for alpha in alphas.get(\"alpha\"):\n",
    "    bnb = BernoulliNB(alpha = alpha)\n",
    "    bnb.fit(train_data, train_labels)\n",
    "    score = bnb.score(dev_data, dev_labels)\n",
    "    print(\"alpha: %f  dev accuracy: %.2f\" %(alpha, score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
