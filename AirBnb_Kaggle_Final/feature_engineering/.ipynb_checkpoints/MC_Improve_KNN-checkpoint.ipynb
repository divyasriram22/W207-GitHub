{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/melaniecostello/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/cross_validation.py:44: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/Users/melaniecostello/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/grid_search.py:43: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. This module will be removed in 0.20.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.grid_search import GridSearchCV\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../train_dev_data/train_data.csv')\n",
    "dev = pd.read_csv('../train_dev_data/dev_data.csv')\n",
    "\n",
    "# Split off training labels & dev labels\n",
    "train_labels = train.country_destination\n",
    "dev_labels = dev.country_destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>date_account_created</th>\n",
       "      <th>timestamp_first_active</th>\n",
       "      <th>date_first_booking</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>signup_method</th>\n",
       "      <th>signup_flow</th>\n",
       "      <th>language</th>\n",
       "      <th>affiliate_channel</th>\n",
       "      <th>affiliate_provider</th>\n",
       "      <th>first_affiliate_tracked</th>\n",
       "      <th>signup_app</th>\n",
       "      <th>first_device_type</th>\n",
       "      <th>first_browser</th>\n",
       "      <th>country_destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>g936neasyy</td>\n",
       "      <td>2013-05-12</td>\n",
       "      <td>20130512210934</td>\n",
       "      <td>2013-05-13</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>NaN</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>linked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>other</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>duq2vabpp2</td>\n",
       "      <td>2013-03-02</td>\n",
       "      <td>20130302054534</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>31.0</td>\n",
       "      <td>facebook</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Mobile Safari</td>\n",
       "      <td>NDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xiymwcsklc</td>\n",
       "      <td>2011-05-17</td>\n",
       "      <td>20110517211429</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>105.0</td>\n",
       "      <td>facebook</td>\n",
       "      <td>2</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>untracked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Mac Desktop</td>\n",
       "      <td>Firefox</td>\n",
       "      <td>NDF</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8kkcksa0dw</td>\n",
       "      <td>2013-12-02</td>\n",
       "      <td>20131202180650</td>\n",
       "      <td>2013-12-11</td>\n",
       "      <td>-unknown-</td>\n",
       "      <td>37.0</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>sem-brand</td>\n",
       "      <td>google</td>\n",
       "      <td>omg</td>\n",
       "      <td>Web</td>\n",
       "      <td>iPad</td>\n",
       "      <td>Mobile Safari</td>\n",
       "      <td>US</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>zk8qx61d9m</td>\n",
       "      <td>2013-11-07</td>\n",
       "      <td>20131107183734</td>\n",
       "      <td>NaN</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>25.0</td>\n",
       "      <td>basic</td>\n",
       "      <td>0</td>\n",
       "      <td>en</td>\n",
       "      <td>direct</td>\n",
       "      <td>direct</td>\n",
       "      <td>linked</td>\n",
       "      <td>Web</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>Chrome</td>\n",
       "      <td>NDF</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           id date_account_created  timestamp_first_active date_first_booking  \\\n",
       "0  g936neasyy           2013-05-12          20130512210934         2013-05-13   \n",
       "1  duq2vabpp2           2013-03-02          20130302054534                NaN   \n",
       "2  xiymwcsklc           2011-05-17          20110517211429                NaN   \n",
       "3  8kkcksa0dw           2013-12-02          20131202180650         2013-12-11   \n",
       "4  zk8qx61d9m           2013-11-07          20131107183734                NaN   \n",
       "\n",
       "      gender    age signup_method  signup_flow language affiliate_channel  \\\n",
       "0  -unknown-    NaN         basic            0       en            direct   \n",
       "1     FEMALE   31.0      facebook            0       en            direct   \n",
       "2  -unknown-  105.0      facebook            2       en            direct   \n",
       "3  -unknown-   37.0         basic            0       en         sem-brand   \n",
       "4     FEMALE   25.0         basic            0       en            direct   \n",
       "\n",
       "  affiliate_provider first_affiliate_tracked signup_app first_device_type  \\\n",
       "0             direct                  linked        Web       Mac Desktop   \n",
       "1             direct               untracked        Web              iPad   \n",
       "2             direct               untracked        Web       Mac Desktop   \n",
       "3             google                     omg        Web              iPad   \n",
       "4             direct                  linked        Web   Windows Desktop   \n",
       "\n",
       "   first_browser country_destination  \n",
       "0         Chrome               other  \n",
       "1  Mobile Safari                 NDF  \n",
       "2        Firefox                 NDF  \n",
       "3  Mobile Safari                  US  \n",
       "4         Chrome                 NDF  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>action</th>\n",
       "      <th>action_type</th>\n",
       "      <th>action_detail</th>\n",
       "      <th>device_type</th>\n",
       "      <th>secs_elapsed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>319.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>search_results</td>\n",
       "      <td>click</td>\n",
       "      <td>view_search_results</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>67753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>301.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>search_results</td>\n",
       "      <td>click</td>\n",
       "      <td>view_search_results</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>22141.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>d1mm9tcy42</td>\n",
       "      <td>lookup</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Windows Desktop</td>\n",
       "      <td>435.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      user_id          action action_type        action_detail  \\\n",
       "0  d1mm9tcy42          lookup         NaN                  NaN   \n",
       "1  d1mm9tcy42  search_results       click  view_search_results   \n",
       "2  d1mm9tcy42          lookup         NaN                  NaN   \n",
       "3  d1mm9tcy42  search_results       click  view_search_results   \n",
       "4  d1mm9tcy42          lookup         NaN                  NaN   \n",
       "\n",
       "       device_type  secs_elapsed  \n",
       "0  Windows Desktop         319.0  \n",
       "1  Windows Desktop       67753.0  \n",
       "2  Windows Desktop         301.0  \n",
       "3  Windows Desktop       22141.0  \n",
       "4  Windows Desktop         435.0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ses = pd.read_csv('../unzipped_files/sessions.csv')\n",
    "ses.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# We're going to attempt to undersample the examples in which NDF is the outcome\n",
    "# Split off rows where NDF is target variable\n",
    "NDF = train[train['country_destination']=='NDF']\n",
    "US = train[train['country_destination']=='US']\n",
    "other = train[((train['country_destination']!='NDF') & (train['country_destination']!='US'))]\n",
    "\n",
    "# Concatenate a portion of NDF with everything else\n",
    "objs = [NDF[:10000], US[:10000], other]\n",
    "new_df = pd.concat(objs, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split off training labels & dev labels\n",
    "train_labels = new_df.country_destination\n",
    "dev_labels = dev.country_destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transform variables we want to use into binary\n",
    "test_cols = ['language', 'gender', 'signup_app']\n",
    "tr_binary_vars = pd.get_dummies(new_df[['language', 'gender', 'signup_app', 'age']], columns=test_cols)\n",
    "\n",
    "dev_binary_vars = pd.get_dummies(dev[['language', 'gender', 'signup_app', 'age']], columns=test_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([], \n",
       "      dtype='|S18')"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Note that training data has two extra languages in it - ca & hr\n",
    "# We need to add dummy columns for ca to the dev data\n",
    "\n",
    "# List of columns in transformed training data & dev data\n",
    "tr_list = list(tr_binary_vars.columns.values)\n",
    "dev_list = list(dev_binary_vars.columns.values)\n",
    "\n",
    "# difference between the sets - tr has language_ca, dev has language_id\n",
    "np.setdiff1d(tr_list, dev_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tr_binary_vars = tr_binary_vars.drop([\"language_ca\"], axis=1)\n",
    "dev_binary_vars = dev_binary_vars.drop([\"language_id\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create arrays based on the variables we want to use\n",
    "train_array = np.array(tr_binary_vars)\n",
    "train_label_array = np.array(train_labels)\n",
    "\n",
    "dev_array = np.array(dev_binary_vars)\n",
    "dev_label_array = np.array(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input contains NaN, infinity or a value too large for dtype('float64').",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-205-c31315400f4d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[0mk_vals\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m50\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m \u001b[0mmod_test\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_label_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdev_label_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2000\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-205-c31315400f4d>\u001b[0m in \u001b[0;36mmod_test\u001b[0;34m(k_vals, train_data, train_labels, dev_data, dev_labels)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m# initialize a variable to hold the predictions\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0mknn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_neighbors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0melem\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m         \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mknn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdev_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/melaniecostello/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/neighbors/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    759\u001b[0m         \"\"\"\n\u001b[1;32m    760\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mKDTree\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mBallTree\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 761\u001b[0;31m             \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"csr\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    762\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    763\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/melaniecostello/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    519\u001b[0m     X = check_array(X, accept_sparse, dtype, order, copy, force_all_finite,\n\u001b[1;32m    520\u001b[0m                     \u001b[0mensure_2d\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mallow_nd\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mensure_min_samples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 521\u001b[0;31m                     ensure_min_features, warn_on_dtype, estimator)\n\u001b[0m\u001b[1;32m    522\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmulti_output\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    523\u001b[0m         y = check_array(y, 'csr', force_all_finite=True, ensure_2d=False,\n",
      "\u001b[0;32m/Users/melaniecostello/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_array\u001b[0;34m(array, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    405\u001b[0m                              % (array.ndim, estimator_name))\n\u001b[1;32m    406\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mforce_all_finite\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m             \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0mshape_repr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_shape_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Users/melaniecostello/anaconda/envs/py27/lib/python2.7/site-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36m_assert_all_finite\u001b[0;34m(X)\u001b[0m\n\u001b[1;32m     56\u001b[0m             and not np.isfinite(X).all()):\n\u001b[1;32m     57\u001b[0m         raise ValueError(\"Input contains NaN, infinity\"\n\u001b[0;32m---> 58\u001b[0;31m                          \" or a value too large for %r.\" % X.dtype)\n\u001b[0m\u001b[1;32m     59\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Input contains NaN, infinity or a value too large for dtype('float64')."
     ]
    }
   ],
   "source": [
    "# Try a model\n",
    "def mod_test(k_vals, train_data, train_labels, dev_data, dev_labels=None):\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "    # We want to evaluate a variety of values for k, so we need\n",
    "    # to enclose our work in a loop.\n",
    "    for elem in k_vals:\n",
    "        \n",
    "        # Create a classifier object, fit our training data &\n",
    "        # initialize a variable to hold the predictions\n",
    "        knn = KNeighborsClassifier(n_neighbors=elem)\n",
    "        knn.fit(train_data, train_labels)\n",
    "        preds = knn.predict(dev_data)\n",
    "        \n",
    "        # We evaluate the accuracy for each value of k by comparing\n",
    "        # the predictions and the labels, then updating values for\n",
    "        # correct and total\n",
    "        correct, total = 0, 0\n",
    "        for pred, label in zip(preds, dev_labels):\n",
    "            if pred == label: \n",
    "                correct += 1\n",
    "            total += 1\n",
    "        print 'For k=%s, total: %3d  correct: %3d  accuracy: %3.4f' %(elem, total, correct, 1.0*correct/total)\n",
    "\n",
    "k_vals = [7, 10, 15, 20, 50]\n",
    "mod_test(k_vals, train_array[:10000], train_label_array[:10000], dev_array[:2000], dev_label_array[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "en    42176\n",
       "zh      258\n",
       "fr      238\n",
       "es      162\n",
       "de      160\n",
       "ko      142\n",
       "it       70\n",
       "ru       69\n",
       "ja       41\n",
       "pt       37\n",
       "nl       24\n",
       "sv       18\n",
       "tr       15\n",
       "da       10\n",
       "pl        9\n",
       "no        7\n",
       "el        6\n",
       "cs        5\n",
       "fi        3\n",
       "th        2\n",
       "hu        2\n",
       "is        1\n",
       "Name: language, dtype: int64"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_df.language.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bin languages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Define a generic function using Pandas replace function\n",
    "def coding(col, codeDict):\n",
    "    colCoded = pd.Series(col, copy=True)\n",
    "    for key, value in codeDict.items():\n",
    "        colCoded.replace(key, value, inplace=True)\n",
    "    return colCoded\n",
    "\n",
    "new_df[\"lang_mod\"] = coding(new_df[\"language\"], {'en':'en', 'zh':'zh', 'fr':'fr', 'es':'es', 'de':'de', 'ko':'ko',\n",
    "                                                'it':'other', 'ru':'other', 'ja':'other', 'pt':'other', 'nl':'other',\n",
    "                                                'sv':'other', 'tr':'other', 'da':'other', 'pl':'other', 'no':'other',\n",
    "                                                'el':'other', 'cs':'other', 'fi':'other', 'th':'other', 'hu':'other',\n",
    "                                                'is':'other', 'id':'other'})\n",
    "\n",
    "dev[\"lang_mod\"] = coding(dev[\"language\"], {'en':'en', 'zh':'zh', 'fr':'fr', 'es':'es', 'de':'de', 'ko':'ko',\n",
    "                                                'it':'other', 'ru':'other', 'ja':'other', 'pt':'other', 'nl':'other',\n",
    "                                                'sv':'other', 'tr':'other', 'da':'other', 'pl':'other', 'no':'other',\n",
    "                                                'el':'other', 'cs':'other', 'fi':'other', 'th':'other', 'hu':'other',\n",
    "                                                'is':'other', 'id':'other'})\n",
    "\n",
    "\n",
    "# Reduce number of english language examples\n",
    "en = new_df[new_df['lang_mod']=='en']\n",
    "other = new_df[new_df['lang_mod']!='en']\n",
    "\n",
    "# Concatenate a portion of en with everything else\n",
    "objs = [en[:20000], other]\n",
    "new_df = pd.concat(objs, axis=0)\n",
    "\n",
    "# Split off training labels & dev labels\n",
    "train_labels = new_df.country_destination\n",
    "dev_labels = dev.country_destination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Transform variables we want to use into binary\n",
    "test_cols = ['lang_mod', 'gender']\n",
    "tr_binary_vars = pd.get_dummies(new_df[['lang_mod', 'gender']], columns=test_cols)\n",
    "\n",
    "dev_binary_vars = pd.get_dummies(dev[['lang_mod', 'gender']], columns=test_cols)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create arrays based on the variables we want to use\n",
    "train_array = np.array(tr_binary_vars)\n",
    "train_label_array = np.array(train_labels)\n",
    "\n",
    "dev_array = np.array(dev_binary_vars)\n",
    "dev_label_array = np.array(dev_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For k=7, total: 2000  correct: 1159  accuracy: 0.5795\n",
      "For k=10, total: 2000  correct: 1157  accuracy: 0.5785\n",
      "For k=15, total: 2000  correct: 1157  accuracy: 0.5785\n",
      "For k=20, total: 2000  correct: 1155  accuracy: 0.5775\n",
      "For k=50, total: 2000  correct: 1154  accuracy: 0.5770\n"
     ]
    }
   ],
   "source": [
    "# Try a model\n",
    "def mod_test(k_vals, train_data, train_labels, dev_data, dev_labels=None):\n",
    "\n",
    "### STUDENT START ###\n",
    "\n",
    "    # We want to evaluate a variety of values for k, so we need\n",
    "    # to enclose our work in a loop.\n",
    "    for elem in k_vals:\n",
    "        \n",
    "        # Create a classifier object, fit our training data &\n",
    "        # initialize a variable to hold the predictions\n",
    "        knn = KNeighborsClassifier(n_neighbors=elem)\n",
    "        knn.fit(train_data, train_labels)\n",
    "        preds = knn.predict(dev_data)\n",
    "        \n",
    "        # We evaluate the accuracy for each value of k by comparing\n",
    "        # the predictions and the labels, then updating values for\n",
    "        # correct and total\n",
    "        correct, total = 0, 0\n",
    "        for pred, label in zip(preds, dev_labels):\n",
    "            if pred == label: \n",
    "                correct += 1\n",
    "            total += 1\n",
    "        print 'For k=%s, total: %3d  correct: %3d  accuracy: %3.4f' %(elem, total, correct, 1.0*correct/total)\n",
    "\n",
    "k_vals = [7, 10, 15, 20, 50]\n",
    "mod_test(k_vals, train_array[:10000], train_label_array[:10000], dev_array[:2000], dev_label_array[:2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda env:py27]",
   "language": "python",
   "name": "conda-env-py27-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
