{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# General libraries.\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parameters added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Month of Account Creation\n",
    "* Season of Account Creation\n",
    "* Year of Account Creation\n",
    "* Age Bin \n",
    "* Language Bin\n",
    "* Days Between Account Creation and Date Freezing Data Collection\n",
    "* Total Number Actions per User\n",
    "* Number unique devices used per user\n",
    "* Longest Action by a user\n",
    "* Total time spent on site per user\n",
    "* The last action a user made \n",
    "* Hour the user first accessed Airbnb\n",
    "* Count of each action in sessions data \n",
    "* Count of each action detail in sessions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_data shape:  (213451, 16)\n",
      "sessions shape:  (10567737, 6)\n",
      "test shape:  (62096, 15)\n"
     ]
    }
   ],
   "source": [
    "# get training and sessions data \n",
    "train = pd.read_csv('../zip_files/train_users_2.csv.zip')\n",
    "test = pd.read_csv('../zip_files/test_users.csv.zip')\n",
    "ses = pd.read_csv('../zip_files/sessions.csv.zip')\n",
    "\n",
    "# rename sessions 'id' column to 'user_id' to correspond to train and test naming convention\n",
    "ses.rename(columns={'user_id': 'id'}, inplace=True)\n",
    "\n",
    "print(\"train_data shape: \", train.shape)\n",
    "print(\"sessions shape: \", ses.shape)\n",
    "print(\"test shape: \", test.shape) # no country_destination column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sessions and train users: 73815\n",
      "sessions and test users: 61668\n"
     ]
    }
   ],
   "source": [
    "ses_id = ses['id'].unique()\n",
    "train_id = train['id'].unique()\n",
    "test_id = test['id'].unique()\n",
    "\n",
    "print(\"sessions and train users:\", len(set(ses_id) & set(train_id)))\n",
    "print(\"sessions and test users:\", len(set(ses_id) & set(test_id)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (213451, 17)\n",
      "test shape:  (62096, 16)\n"
     ]
    }
   ],
   "source": [
    "# create param: month of account creation\n",
    "def parse_month(col):\n",
    "    start = col.find(\"-\")\n",
    "    end = col.find(\"-\", start+1)\n",
    "    month = col[start+1:end]\n",
    "    return month\n",
    "\n",
    "train[\"month_created\"] = train.date_account_created.apply(parse_month)\n",
    "test[\"month_created\"] = test.date_account_created.apply(parse_month)\n",
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (213451, 18)\n",
      "test shape:  (62096, 17)\n"
     ]
    }
   ],
   "source": [
    "# create param: season of account creation\n",
    "def parse_season(col):\n",
    "    if col in ('12', '01', '02'):\n",
    "        return 'Winter'\n",
    "    elif col in ('03', '04', '05'):\n",
    "        return 'Spring'\n",
    "    elif col in ('06', '07', '08'):\n",
    "        return 'Summer'\n",
    "    else:\n",
    "        return 'Fall'\n",
    "    \n",
    "train[\"season_created\"] = train.month_created.apply(parse_season)\n",
    "test[\"season_created\"] = test.month_created.apply(parse_season)\n",
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (213451, 19)\n",
      "test shape:  (62096, 18)\n"
     ]
    }
   ],
   "source": [
    "# create param: year of account creation\n",
    "def parse_year(col):\n",
    "    stop = col.find(\"-\")\n",
    "    year = col[:stop]\n",
    "    return year\n",
    "\n",
    "train[\"year_created\"] = train.date_account_created.apply(parse_year)\n",
    "test[\"year_created\"] = test.date_account_created.apply(parse_year)\n",
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (213451, 20)\n",
      "test shape:  (62096, 19)\n"
     ]
    }
   ],
   "source": [
    "# create param: age bin\n",
    "def bin_age(col):\n",
    "    if col >= 65 and col < 100:\n",
    "        return \"100+\"\n",
    "    elif col >=45 and col < 65:\n",
    "        return \"45-65\"\n",
    "    elif col >=30 and col < 45:\n",
    "        return \"30-45\"\n",
    "    elif col >= 0 and col < 30:\n",
    "        return \"Under30\"\n",
    "    else:\n",
    "        return \"Unknown\"\n",
    "    \n",
    "train[\"bin_age\"] = train.age.apply(bin_age)\n",
    "test[\"bin_age\"] = test.age.apply(bin_age)\n",
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # create param: book/no-book \n",
    "# def booking_flag(col):\n",
    "#     if type(col) != 'str':\n",
    "#         return 0\n",
    "#     else:\n",
    "#         return 1\n",
    "\n",
    "# train[\"booking_flag\"] = train.date_first_booking.apply(booking_flag)\n",
    "# test[\"booking_flag\"] = test.date_first_booking.apply(booking_flag) # will be 0 for all rows\n",
    "# print(\"train shape: \", train.shape) \n",
    "# print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (213451, 21)\n",
      "test shape:  (62096, 20)\n"
     ]
    }
   ],
   "source": [
    "# create param: language bin\n",
    "def bin_lang(col):\n",
    "    if col in ('en', 'zh', 'es', 'fr'):\n",
    "        return col\n",
    "    else:\n",
    "        return 'other'\n",
    "\n",
    "train[\"bin_lang\"] = train.language.apply(bin_lang)\n",
    "test[\"bin_lang\"] = test.language.apply(bin_lang)\n",
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # create param: days between account creation and first booking\n",
    "# # some values negative because people created accounts AFTER they booked\n",
    "\n",
    "# train_x = pd.to_datetime(train[\"date_first_booking\"]) - pd.to_datetime(train[\"date_account_created\"])\n",
    "# train[\"days_delta_creation_booking\"] = train_x / np.timedelta64(1, 'D')\n",
    "\n",
    "# test_x = pd.to_datetime(test[\"date_first_booking\"]) - pd.to_datetime(test[\"date_account_created\"])\n",
    "# test[\"days_delta_creation_booking\"] = test_x / np.timedelta64(1, 'D')\n",
    "\n",
    "# print(\"train shape: \", train.shape)\n",
    "# print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (213451, 22)\n",
      "test shape:  (62096, 21)\n"
     ]
    }
   ],
   "source": [
    "# create param: days between account creation and date of data collection cut-off (last day of datasets)\n",
    "train_last = max(train[\"date_account_created\"]) # '2014-06-30'\n",
    "train_y = pd.to_datetime(max(train[\"date_account_created\"])) - pd.to_datetime(train[\"date_account_created\"])\n",
    "train[\"days_since_creation\"] = train_y / np.timedelta64(1, 'D')\n",
    "\n",
    "test_last = max(test[\"date_account_created\"]) # '2014-09-30'\n",
    "train_y = pd.to_datetime(max(train[\"date_account_created\"])) - pd.to_datetime(train[\"date_account_created\"])\n",
    "test[\"days_since_creation\"] = train_y / np.timedelta64(1, 'D')\n",
    "\n",
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (213451, 23)\n",
      "test shape:  (62096, 22)\n"
     ]
    }
   ],
   "source": [
    "# Create param: Hour the user first accessed Airbnb\n",
    "# will be 0 for all test users\n",
    "def first_hour_(x):\n",
    "    return int(str(x)[8:10])\n",
    "\n",
    "train['first_hour'] = train.timestamp_first_active.apply(first_hour_)\n",
    "test['first_hour'] = test.timestamp_first_active.apply(first_hour_)\n",
    "\n",
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (213451, 24)\n",
      "test shape:  (62096, 23)\n"
     ]
    }
   ],
   "source": [
    "# Create param: Total number of actions per user\n",
    "z = pd.DataFrame({'count_actions': ses['id'].value_counts()})\n",
    "z['id']= z.index\n",
    "z.index = list(range(0,len(z))) # sets index as numeric\n",
    "\n",
    "train = pd.merge(train, z, on=['id', 'id'], how='left')\n",
    "test = pd.merge(test, z, on=['id', 'id'], how='left')\n",
    "\n",
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (213451, 25)\n",
      "test shape:  (62096, 24)\n"
     ]
    }
   ],
   "source": [
    "# Create param: Number unique devices used per user\n",
    "# \"unknown\" device type counts as a device\n",
    "y = ses.groupby('id')['device_type'].nunique()  # Df where sessions is grouped by user, and unique number of devices used is returned\n",
    "y = y.to_frame()  # Converts pandas series to df\n",
    "y['id']= y.index   # Changes user_id from index to column\n",
    "y.index = list(range(0,len(y))) # sets index as numeric\n",
    "y.columns = ['number_devices', 'id']\n",
    "\n",
    "train = pd.merge(train, y, on=['id', 'id'], how='left')\n",
    "test = pd.merge(test, y, on=['id', 'id'], how='left')\n",
    "\n",
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (213451, 26)\n",
      "test shape:  (62096, 25)\n"
     ]
    }
   ],
   "source": [
    "# Create param: Longest Action by a user\n",
    "max_time = ses.groupby('id')['secs_elapsed'].max()  # Df where sessions is grouped by user, and unique number of devices used is returned\n",
    "max_time = max_time.to_frame()  # Converts pandas series to df\n",
    "max_time['id']= max_time.index   # Changes user_id from index to column\n",
    "max_time.index = list(range(0,len(max_time))) # sets index as numeric\n",
    "max_time.columns = ['longest_session', 'id']\n",
    "\n",
    "train = pd.merge(train, max_time, on=['id', 'id'], how='left')\n",
    "test = pd.merge(test, max_time, on=['id', 'id'], how='left')\n",
    "\n",
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (213451, 27)\n",
      "test shape:  (62096, 26)\n"
     ]
    }
   ],
   "source": [
    "# Create param: Total time spent on site per user\n",
    "total_time = ses.groupby('id')['secs_elapsed'].sum()  # Df where sessions is grouped by user, and unique number of devices used is returned\n",
    "total_time = total_time.to_frame()  # Converts pandas series to df\n",
    "total_time['id']= total_time.index   # Changes user_id from index to column\n",
    "total_time.index = list(range(0,len(total_time))) # sets index as numeric\n",
    "total_time.columns = ['total_time', 'id']\n",
    "\n",
    "train = pd.merge(train, total_time, on=['id', 'id'], how='left')\n",
    "test = pd.merge(test, total_time, on=['id', 'id'], how='left')\n",
    "\n",
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (213451, 28)\n",
      "test shape:  (62096, 27)\n"
     ]
    }
   ],
   "source": [
    "# Create param: The last action a user made \n",
    "last_action = ses.groupby('id')['action_detail'].last()\n",
    "last_action = last_action.to_frame() \n",
    "last_action['id'] = last_action.index\n",
    "last_action.index = list(range(0,len(last_action)))\n",
    "last_action.columns = ['last_action', 'id']\n",
    "\n",
    "train = pd.merge(train, last_action, on=['id', 'id'], how='left')\n",
    "test = pd.merge(test, last_action, on=['id', 'id'], how='left')\n",
    "\n",
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (213451, 28)\n",
      "test shape:  (62096, 27)\n",
      "train w actions shape:  (213451, 387)\n",
      "test w actions shape:  (62096, 386)\n"
     ]
    }
   ],
   "source": [
    "# Create params: Count of each action in sessions data\n",
    "actions = pd.crosstab(index=ses[\"id\"], columns=ses[\"action\"])\n",
    "\n",
    "# reset index so user_id is its own column\n",
    "actions.reset_index(level=0, inplace=True)\n",
    "\n",
    "# Create new dataframe that uses user data and sessions action count data\n",
    "train_w_actions = pd.merge(train, actions, on=['id', 'id'], how='left')\n",
    "test_w_actions = pd.merge(test, actions, on=['id', 'id'], how='left')\n",
    "\n",
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)\n",
    "\n",
    "print(\"train w actions shape: \", train_w_actions.shape)\n",
    "print(\"test w actions shape: \", test_w_actions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (213451, 28)\n",
      "test shape:  (62096, 27)\n",
      "train w actions shape:  (213451, 542)\n",
      "test w actions shape:  (62096, 541)\n"
     ]
    }
   ],
   "source": [
    "# Create params: Count of each action_detail in sessions data\n",
    "action_detail = pd.crosstab(index=ses[\"id\"], columns=ses[\"action_detail\"])\n",
    "\n",
    "# reset index so user_id is its own column\n",
    "action_detail.reset_index(level=0, inplace=True)\n",
    "\n",
    "train_w_actions = pd.merge(train_w_actions, action_detail, on=['id', 'id'], how='left')\n",
    "test_w_actions = pd.merge(test_w_actions, action_detail, on=['id', 'id'], how='left')\n",
    "\n",
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)\n",
    "\n",
    "print(\"train w actions shape: \", train_w_actions.shape)\n",
    "print(\"test w actions shape: \", test_w_actions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape:  (213451, 27)\n",
      "test shape:  (62096, 26)\n",
      "train w actions shape:  (213451, 541)\n",
      "test w actions shape:  (62096, 540)\n"
     ]
    }
   ],
   "source": [
    "# Drop 'date_first_booking' from train and test set\n",
    "train = train.drop('date_first_booking', 1)\n",
    "test = test.drop('date_first_booking', 1)\n",
    "\n",
    "train_w_actions = train_w_actions.drop('date_first_booking', 1)\n",
    "test_w_actions = test_w_actions.drop('date_first_booking', 1)\n",
    "\n",
    "print(\"train shape: \", train.shape)\n",
    "print(\"test shape: \", test.shape)\n",
    "\n",
    "print(\"train w actions shape: \", train_w_actions.shape)\n",
    "print(\"test w actions shape: \", test_w_actions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-21-5a2bbfe8d0e8>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/test_combined.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain_w_actions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/train_combined_actions.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mtest_w_actions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mto_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'../data/test_combined_actions.csv'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m','\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\Users\\cendy\\Anaconda3\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36mto_csv\u001b[0;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, line_terminator, chunksize, tupleize_cols, date_format, doublequote, escapechar, decimal)\u001b[0m\n\u001b[1;32m   1381\u001b[0m                                      \u001b[0mdoublequote\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdoublequote\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1382\u001b[0m                                      escapechar=escapechar, decimal=decimal)\n\u001b[0;32m-> 1383\u001b[0;31m         \u001b[0mformatter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1384\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1385\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpath_or_buf\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\Users\\cendy\\Anaconda3\\lib\\site-packages\\pandas\\formats\\format.py\u001b[0m in \u001b[0;36msave\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1473\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcsv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mwriter_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1474\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1475\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1476\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1477\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\Users\\cendy\\Anaconda3\\lib\\site-packages\\pandas\\formats\\format.py\u001b[0m in \u001b[0;36m_save\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1574\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1575\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1576\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1577\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1578\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_save_chunk\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstart_i\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mend_i\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mc:\\Users\\cendy\\Anaconda3\\lib\\site-packages\\pandas\\formats\\format.py\u001b[0m in \u001b[0;36m_save_chunk\u001b[0;34m(self, start_i, end_i)\u001b[0m\n\u001b[1;32m   1600\u001b[0m                                         quoting=self.quoting)\n\u001b[1;32m   1601\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1602\u001b[0;31m         \u001b[0mlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite_csv_rows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mix\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnlevels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcols\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwriter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1603\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1604\u001b[0m \u001b[1;31m# from collections import namedtuple\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mpandas\\lib.pyx\u001b[0m in \u001b[0;36mpandas.lib.write_csv_rows (pandas\\lib.c:20752)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mc:\\Users\\cendy\\Anaconda3\\lib\\encodings\\cp1252.py\u001b[0m in \u001b[0;36mencode\u001b[0;34m(self, input, final)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalEncoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mencode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinal\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m---> 19\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcharmap_encode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0merrors\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mencoding_table\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     20\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[1;32mclass\u001b[0m \u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcodecs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mIncrementalDecoder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Export to CSV\n",
    "train.to_csv('./train_combined.csv',sep=',')\n",
    "test.to_csv('./test_combined.csv',sep=',')\n",
    "\n",
    "train_w_actions.to_csv('./train_combined_actions.csv',sep=',')\n",
    "test_w_actions.to_csv('./test_combined_actions.csv',sep=',')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing users in train set that pre-date sessions data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove users that pre-date sessions data\n",
    "modern_train = train.copy()\n",
    "\n",
    "modern_train_w_actions = train_w_actions.copy()\n",
    "\n",
    "# drop rows that predate sessions information (have no action count)\n",
    "modern_train = modern_train[pd.isnull(modern_train.count_actions) != True] \n",
    "modern_train_w_actions = modern_train_w_actions[pd.isnull(modern_train_w_actions.count_actions) != True] \n",
    "\n",
    "# reset index\n",
    "modern_train.reset_index(drop=True, inplace=True) \n",
    "modern_train_w_actions.reset_index(drop=True, inplace=True)\n",
    "\n",
    "print(\"modern train shape: \", modern_train.shape)\n",
    "print(\"modern train w actions shape: \", modern_train_w_actions.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Export 'modern' datasets to CSV\n",
    "modern_train.to_csv('./modern_train_combined.csv',sep=',')\n",
    "modern_train_w_actions.to_csv('./modern_train_combined_actions.csv',sep=',')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
